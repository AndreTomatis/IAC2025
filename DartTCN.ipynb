{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aad8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82acd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31829328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV\n",
    "df = pd.read_csv(\"./2/dataset_sun_wind.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c93e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"period\"] == \"train_a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae31fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time(time_str):\n",
    "    days, time = time_str.split(' days ')\n",
    "    hours, minutes, seconds = map(int, time.split(':'))\n",
    "    return pd.Timedelta(days=int(days), hours=hours, minutes=minutes, seconds=seconds)\n",
    "\n",
    "\n",
    "df[\"timedelta\"] = df[\"timedelta\"].apply(parse_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7d0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake datetime starting point\n",
    "start_time = pd.Timestamp(\"2020-01-01\")\n",
    "df[\"timestamp\"] = start_time + pd.to_timedelta(df[\"timedelta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a3ea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TimeSeries objects\n",
    "target_series = TimeSeries.from_dataframe(df, \n",
    "                                          time_col=\"timestamp\", \n",
    "                                          value_cols=\"dst\", \n",
    "                                          freq=\"T\")  # target only\n",
    "\n",
    "past_covariates = TimeSeries.from_dataframe(df,\n",
    "                                            time_col=\"timestamp\", \n",
    "                                            value_cols=[\"bt\", \n",
    "                                                        \"density\",\n",
    "                                                        \"temperature\",\n",
    "                                                        \"bx_gse\",\n",
    "                                                        \"by_gse\",\n",
    "                                                        \"bz_gse\",\n",
    "                                                        \"gse_x\",\n",
    "                                                        \"gse_y\", \n",
    "                                                        \"gse_z\", \n",
    "                                                        \"speed\"],\n",
    "                                            freq=\"T\")  # inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e5f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "scaler_target = Scaler()\n",
    "scaler_covariates = Scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b69a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_series = scaler_target.fit_transform(target_series)\n",
    "past_covariates = scaler_covariates.fit_transform(past_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23cad8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "train_target = target_series[:-50]\n",
    "val_target = target_series[-50:]\n",
    "\n",
    "train_covs = past_covariates[:-50]\n",
    "val_covs = past_covariates[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4942d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrea/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from darts.models import TCNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93e0f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCNModel(\n",
    "    input_chunk_length=60,\n",
    "    output_chunk_length=10,\n",
    "    n_epochs=100,\n",
    "    random_state=42,\n",
    "    dropout=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "694ff052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | res_blocks      | ModuleList       | 332    | train\n",
      "-------------------------------------------------------------\n",
      "332       Trainable params\n",
      "0         Non-trainable params\n",
      "332       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f859b44579b249a996ad1545560439cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                            | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TCNModel(output_chunk_shift=0, kernel_size=3, num_filters=3, num_layers=None, dilation_base=2, weight_norm=False, dropout=0.1, input_chunk_length=60, output_chunk_length=10, n_epochs=100, random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_target, past_covariates=train_covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2c5afc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ValueError: For the given forecasting case, the provided `past_covariates` at series sequence index `0` do not extend far enough into the past. The `past_covariates` must start at or before time step `2020-04-07 01:22:00`, whereas now the start is at time step `2020-04-07 02:22:00`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For the given forecasting case, the provided `past_covariates` at series sequence index `0` do not extend far enough into the past. The `past_covariates` must start at or before time step `2020-04-07 01:22:00`, whereas now the start is at time step `2020-04-07 02:22:00`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1c/4j6xkzy142l_r26j20bypc340000gn/T/ipykernel_83615/3144377476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m forecast = model.predict(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpast_covariates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_covs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/utils/torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/models/forecasting/torch_forecasting_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, n, series, past_covariates, future_covariates, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, show_warnings, random_state)\u001b[0m\n\u001b[1;32m   1636\u001b[0m         )\n\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m         predictions = self.predict_from_dataset(\n\u001b[0m\u001b[1;32m   1639\u001b[0m             \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/utils/torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/models/forecasting/torch_forecasting_model.py\u001b[0m in \u001b[0;36mpredict_from_dataset\u001b[0;34m(self, n, dataset, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, dataloader_kwargs, mc_dropout, predict_likelihood_parameters, random_state, values_only)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# check that covariates and dimensions are matching what we had during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         self._validate_predict_sample(\n\u001b[0;32m-> 1743\u001b[0;31m             \u001b[0mtrain_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m         )\n\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/utils/data/torch_datasets/inference_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m         )\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         idx_bounds = self._memory_indexer(\n\u001b[0m\u001b[1;32m    258\u001b[0m             \u001b[0mseries_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mseries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/utils/data/torch_datasets/dataset.py\u001b[0m in \u001b[0;36m_memory_indexer\u001b[0;34m(self, series_idx, series, shift, input_chunk_length, output_chunk_length, end_of_output_idx, past_covariates, future_covariates, sample_weight, n)\u001b[0m\n\u001b[1;32m    167\u001b[0m                     \u001b[0;31m# either feature starts too late or ends too early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                         raise_log(\n\u001b[0m\u001b[1;32m    170\u001b[0m                             ValueError(\n\u001b[1;32m    171\u001b[0m                                 \u001b[0;34mf\"For the given forecasting case, the provided `{main_feat_type.value}` at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/darts/logging.py\u001b[0m in \u001b[0;36mraise_log\u001b[0;34m(exception, logger)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For the given forecasting case, the provided `past_covariates` at series sequence index `0` do not extend far enough into the past. The `past_covariates` must start at or before time step `2020-04-07 01:22:00`, whereas now the start is at time step `2020-04-07 02:22:00`."
     ]
    }
   ],
   "source": [
    "forecast = model.predict(\n",
    "    n=10,\n",
    "    past_covariates=val_covs,\n",
    ")\n",
    "\n",
    "# Inverse scale\n",
    "forecast = scaler_target.inverse_transform(forecast)\n",
    "val_target = scaler_target.inverse_transform(val_target)\n",
    "\n",
    "# Plot\n",
    "val_target.plot(label=\"True\")\n",
    "forecast.plot(label=\"Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a5534c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62951"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "i = 0\n",
    "val = train_target.all_values()\n",
    "for el in val:\n",
    "    if np.isnan(el[0][0]):\n",
    "        i+=1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8580e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
